%\documentclass[journal,10pt,onecolumn,draftcls]{IEEEtran}
\documentclass[journal,10pt,onecolumn]{IEEEtran}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{float}
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
\title{Individual Project 1: OpenMP}
%

\author{Jeremy Wright}

% The paper headers
\markboth{CSE430 Individual Project 1: OpenMP}
{CSE430 Individual Project 1: OpenMP}

% make the title area
\maketitle


\begin{abstract}
%\boldmath
Parallel code is difficult to write and test, however the OpenMP's set of 
extensions allow one to add coarse grained parallelism to a system. This paper 
is a look transforming a formerly serial program into a highly parallel one using 
only OpenMP constructs.
\end{abstract}

\listoffigures
\newpage 

\IEEEpeerreviewmaketitle

\section{Introduction}

\IEEEPARstart{O}{penMP} allows one to quickly sprinkle bits of parallelism throughout
a serial program and using a profiler such as Intel's Parallel Studio Amplifier, measure 
the speedup.  OpenMP, however, is not a panacea for all parallelism. For example, OpenMP primitives
cannot parallelize C++ iterators.  Despite these 
subtle limitations, OpenMP is an extremely powerful platform for introducing parallelism
into applications and algorithms.  We use Conway's game of life to demonstrate how 
data decomposition is an important component in accelerating parallel programs. Then we 
use intentionally unbalanced matrices to demonstrate OpenMP's loading mechanisms.

\hfill \today

\section{Game of Life}
Conway's Game of Life is a dramatic demonstration that a seemingly complex system
such as cell mitosis can be governed by a set of simple rules. As a demonstration of
OpenMP's simplicity I implemented a single class drive the Game of Life. Then by 
overriding a few key methods, dynamically run different threading models. 

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol
\subsection{Data Decomposition}
I defined 3 threading models to test OpenMP's performance impact. I defined a threading model
per how I decomposed the data.  I use 3 segmentations division by rows, division by columns, 
division by regions.  The Intel Parallel Studio Tools were key to measuring impact of of omp
for each data segmentation. 

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/utilization_compared.png}
\caption{CPU Utilization between different threading models on a 6 core machine.}
\label{fig:gol_cpu_utilization}
\end{center}
\end{figure*}

All tests were run on a 6-core AMD Phenom II processor, in Linux. Figure~\ref{fig:gol_cpu_utilization},
is a dramatic illustration of the performance boost OMP offers.  The row and column divisions are not 
surprisingly similar, however I was surprise to find that the performance of either was not much better 
than the single threaded model.  However dividing the Game of Life into regions offered a dramatic
boost is CPU utilization.  

\section{Unbalanced Matrices}

\subsection{Intertask Dependency}

\subsubsection{Manual Load Balance}

\begin{equation}
\sum\limits_{a}^b (i + 1) = \frac{-(a + b + 2)(a - b -1)}{2}
\end{equation}
a and b define column numbers.  This equation counts the number of 1's in the 
column of an upper triangular matrix. Use this equation one can balance the number of 
multiplications across sets of columns.  For a 2000 column matrix across 6 processors 
we have the following set of equations.
\begin{eqnarray}
\lefteqn{\frac{-(0 + b + 2)(0 - b -1)}{2}} \\
& = & \frac{-(b + c + 2)(b - c -1)}{2} \\
& = & \frac{-(c + d + 2)(c - d -1)}{2} \\
& = & \frac{-(d + e + 2)(d - e -1)}{2} \\
& = & \frac{-(e + 1999 + 2)(e - 1999 -1)}{2}
\end{eqnarray}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/matrix_without_dynamic_schedule_cpu_usage.png}
\caption{Matrix Multiply CPU Utilization using Standard Parallel for.}
\label{fig:matrix_wo_dynamic_schedule_cpu_usage}
\end{center}
\end{figure*}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/matrix_without_dynamic_schedule_thread_concurrency.png}
\caption{Matrix Multiply Thread Concurrency using with Standard Parallel for.}
\label{fig:matrix_wo_dynamic_schedule_concurrency}
\end{center}
\end{figure*}

Applying this method results still results in a poor load balance.  
Figure~\ref{fig:matrix_wo_dynamic_schedule_concurrency} demonstrates that the threads have a high 
concurrency, but, as Figure~\ref{fig:matrix_wo_dynamic_schedule_cpu_usage} shows, a very poor CPU 
utilization. I used Newton's method to find a solution. This will determine the precise slice of
 columns which will give an even split. However the bookkeeping has a diminishing 
return.  However OpenMP offers a simpler, automatic solution.

\subsection{Dynamic Load Balance}
OpenMP has a accepts a number of parameters called clauses. The Scheduling clause allows
for a dynamic load balancing across the OpenMP threads. 

\lstset{language=C,
    breaklines=true,
    basicstyle=\footnotesize,
    caption={Automatic Load Balancing with schedule clause},
    captionpos=b}
\begin{lstlisting}
int const chunk = size%omp_get_num_threads();
#pragma omp parallel for schedule(dynamic, chunk)
\end{lstlisting}
\label{lst:AutomaticLoadBalancing}
Solving this load imbalance is simple as code Listing \ref{lst:AutomaticLoadBalancing}.

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/matrix_dynamic_schedule_cpu_usage.png}
\caption{Matrix Multiply CPU Usage using Dynamic Thread Balancing.}
\label{fig:matrix_dynamic_schedule_cpu_usage}
\end{center}
\end{figure*}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/matrix_dynamic_schedule_thread_concurrency.png}
\caption{Matrix Multiply Thread Concurrency using Dynamic Thread Balancing.}
\label{fig:matrix_dynamic_schedule_concurrency}
\end{center}
\end{figure*}



\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/12_threaded_matrix_thread_cpu_usage_histogram.png}
\caption{CPU Utilization forcing 12 threads.}
\label{fig:12_threaded_matrix_cpu_usage}
\end{center}
\end{figure*}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/12_threaded_matrix_thread_concurrent_histogram.png}
\caption{Thread Concurrency forcing 12 threads.}
\label{fig:12_threaded_matrix_concurrent}
\end{center}
\end{figure*}


\section{Conclusion}
OpenMP makes adding parallelism to a given program easy. The constructs allow one to sprinkle
parallel code throughout the program, and the measure the performance boost. Sometimes it
may be prudent to dive in deeper and manually thread some section of code, but if OpenMP
meets the need, then its a low-cost mechanism, widely supported mechanism.



\appendices
\section{Intel Parallel Studio}
To evaluate the memory tool, I intentionally put some memory leaks in my code 
to see what parallel studio would do.  Valgrind's memory manager finds a lot of 
false positives.You have to wade through piles of innocuous "errors" before you 
find the real ones. Valgrind is excellent, and it does find all the errors but, 
I have found, there is a learning curve on knowing what errors are real, and 
which are superficial. 

It is really satisfying to see the No Memory Leaks found on the Intel tool. I am 
confident that the report is accurate, whereas with Valgrind I'm never 100\% sure that I recovered all my bugs.

For the performance profiling, the profile does slow down execution just as 
Valgrind, but the slowness didn't seem to be as excessive.  The Intel tool 
seemed to profile faster than Valgrind does.  This is purely subjective, as 
I didn't make any comparative measurements.  Some of the graphs are hard to 
understand. And I would really like to sprinkle profile pragma's throughout my 
code to profile smaller sections e.g at the scope level. I don't know of a tool 
that does this (Maybe a thesis topic :-).  But something that allows you to name 
profile sections that the will be reported separately.  

It's great tool suite. I don't have an Intel processor, so some of the profilers 
wouldn't work, and the errors were non-obvious, but overall the tool is great, and 
I really like that it runs on Linux.

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/fileMep7k0_Memory_Analysis.png}
\caption{Intel Inspector with Debug Symbols enabled.}
\label{fig:intentional_memory_leak}
\end{center}
\end{figure*}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.5\textwidth]{figures/ChangeSet14_Memory.png}
\caption{Game of Life: All Memory Leaks Fixed.}
\label{fig:inspector_clean_memory}
\end{center}
\end{figure*}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.5\textwidth]{figures/ChangeSet14.png}
\caption{Game of Life: All Deadlocks and Data Races Fixed.}
\label{fig:inspector_clean_deadlocks}
\end{center}
\end{figure*}

\begin{figure*}[!t]
\begin{center}
\includegraphics[width=0.5\textwidth]{figures/Data_Race_Anaylsis.png}
\caption{Game of Life: Data Race found on the Update List.}
\label{fig:inspector_data_race_allocator}
\end{center}
\end{figure*}

\section{Matrix Multiplication}




% that's all folks
\end{document}


